#!/usr/bin/env python3
"""
BER vs å¢ç›Šåˆ†æ (Bit Error Rate Analysis)

æµç¨‹:
  1. å¯¹ ISO-Texp æ•°æ®é›†ä¸­æ¯å¼ å›¾ç‰‡è¿è¡Œè§£è°ƒï¼Œè®¡ç®— BER
  2. æŒ‰ç­‰æ•ˆå¢ç›Šåˆ†ç»„ï¼Œç»˜åˆ¶ BER vs å¢ç›Šæ›²çº¿
  3. æ¨¡æ‹Ÿå•æ¬¡å¢ç›Šä¼˜åŒ–ç®—æ³•ï¼ŒéªŒè¯èƒ½å¦å°†å·¥ä½œç‚¹ç§»åˆ°æ›´ä½ BER

è¾“å‡º: results/ber_analysis/
"""

import sys
import warnings
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import cv2
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt

matplotlib.rcParams['font.family'] = ['Hiragino Sans GB', 'Arial Unicode MS',
                                      'PingFang SC', 'SimHei', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False

# æ·»åŠ é¡¹ç›® src è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from occ_gain_opt.experiment_loader import ExperimentLoader

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è·¯å¾„å¸¸é‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR   = Path(__file__).parent.parent
LABEL_CSV  = BASE_DIR / 'results/base_data/Mseq_32_original.csv'
ISO_TEXP   = BASE_DIR / 'ISO-Texp'
OUTPUT_DIR = BASE_DIR / 'results/ber_analysis'

DATA_BITS   = 32      # p32: æ¯åŒ…æ•°æ®ä½æ•°
TARGET_GRAY = 242.25  # å¢ç›Šä¼˜åŒ–ç›®æ ‡ç°åº¦ (255 Ã— 0.95)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è§£è°ƒå·¥å…·å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_ground_truth(csv_path: Path, n_bits: int = DATA_BITS) -> np.ndarray:
    """ä» Mseq CSV åŠ è½½å‰ n_bits ä½çœŸå€¼æ¯”ç‰¹"""
    df = pd.read_csv(str(csv_path), skiprows=5, header=0)
    bits = df.iloc[:, 1].astype(int).to_numpy()
    return bits[:n_bits]


def polyfit_threshold(y: np.ndarray, degree: int = 3) -> np.ndarray:
    """ä¸‰é˜¶å¤šé¡¹å¼æ‹ŸåˆåŠ¨æ€é˜ˆå€¼ï¼ˆä¸ 002_demod_all-exp.py ä¸€è‡´ï¼‰"""
    x = np.arange(1, len(y) + 1)
    coeffs = np.polyfit(x, y, degree)
    return np.polyval(coeffs, x)


def find_sync(rr: np.ndarray,
              head_len: int = 8,
              max_head_len: int = 100,
              max_len_diff: int = 5,
              last_header_len: Optional[int] = None) -> Tuple[int, int, int]:
    """
    æ£€æµ‹åŒæ­¥å¤´ï¼Œè¿”å› (ç­‰æ•ˆä½é•¿ equ, payload èµ·å§‹ä½ç½®, sync èµ·å§‹ä½ç½®)
    é€»è¾‘ä¸ 002_demod_all-exp.py å®Œå…¨ç›¸åŒã€‚
    """
    runs = []
    p = 0
    while p < len(rr):
        if rr[p] == 1:
            q = p
            while q < len(rr) and rr[q] == 1:
                q += 1
            length = q - p
            if head_len <= length <= max_head_len:
                runs.append((p, q - 1, length))
            p = q
        else:
            p += 1

    if not runs:
        raise ValueError("æœªæ£€æµ‹åˆ°æœ‰æ•ˆåŒæ­¥æ®µ")

    runs_sorted = sorted(runs, key=lambda x: x[2], reverse=True)

    if last_header_len is not None:
        filtered = [r for r in runs_sorted
                    if abs(r[2] - last_header_len) <= max_len_diff]
        if filtered:
            runs_sorted = filtered

    h1_start, h1_end, len1 = runs_sorted[0]
    h2_start = h2_end = len2 = None

    for run in runs_sorted[1:]:
        if abs(run[2] - len1) <= max_len_diff:
            h2_start, h2_end, len2 = run
            break

    if h2_start is not None:
        payload_start = min(h1_end, h2_end) + 1
        equ = round(abs((len1 + len2) / (head_len * 2)))
        sync_header_start = min(h1_start, h2_start)
    else:
        payload_start = h1_end + 1
        equ = round(len1 / head_len)
        sync_header_start = h1_start

    return equ, payload_start, sync_header_start


def recover_data(rr: np.ndarray, payload_start: int,
                 equ_len: int) -> np.ndarray:
    """æ¸¸ç¨‹è§£ç ï¼Œè¿˜åŸæ•°æ®æ¯”ç‰¹ï¼ˆä¸ 002_demod_all-exp.py ä¸€è‡´ï¼‰"""
    p = payload_start
    res = []
    for i in range(payload_start, len(rr) - 1):
        if rr[i + 1] != rr[i]:
            q = i + 1
            width = q - p
            cnt = round(width / equ_len)
            res.extend([rr[i]] * cnt)
            p = q
    return np.array(res, dtype=int)


def demodulate_image(img_bgr: np.ndarray) -> dict:
    """
    å¯¹å•å¼  BGR å›¾åƒè¿è¡Œå®Œæ•´è§£è°ƒæµæ°´çº¿ï¼Œè¿”å›:
      status   : 'ok' | 'sync_fail' | 'short' | 'flat'
      bits     : np.ndarray (é•¿åº¦ <= DATA_BITS)
      equ      : ä¼°è®¡ä½å‘¨æœŸ (è¡Œæ•°/bit)
      sync_start: åŒæ­¥å¤´èµ·å§‹è¡Œ
    """
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY).astype(np.float64)

    # è¡Œå‡å€¼æ›²çº¿
    column = np.mean(gray, axis=1)
    std = np.std(column)
    if std < 1e-6:
        return {'bits': np.array([], dtype=int), 'status': 'flat',
                'equ': 0, 'sync_start': -1}

    y = (column - np.mean(column)) / std
    threshold = polyfit_threshold(y, degree=3)
    rr = (y - threshold > 0).astype(int)

    try:
        equ, payload_start, sync_start = find_sync(rr)
    except ValueError:
        return {'bits': np.array([], dtype=int), 'status': 'sync_fail',
                'equ': 0, 'sync_start': -1}

    if equ < 1:
        equ = 1

    raw = recover_data(rr, payload_start, equ)
    # è·³è¿‡ç¬¬ä¸€ä½ï¼ˆæ¸¸ç¨‹è¾¹ç•Œä¼ªåƒï¼‰ï¼Œå†å– DATA_BITS ä½
    bits = raw[1: DATA_BITS + 1]

    if len(bits) < DATA_BITS // 2:
        return {'bits': bits, 'status': 'short',
                'equ': equ, 'sync_start': sync_start}

    return {'bits': bits, 'status': 'ok',
            'equ': equ, 'sync_start': sync_start}


def compute_ber(decoded: np.ndarray, truth: np.ndarray) -> float:
    """è®¡ç®—è¯¯ç ç‡ï¼›è‹¥è§£ç é•¿åº¦ä¸è¶³åˆ™åªæ¯”è¾ƒæœ‰æ•ˆéƒ¨åˆ†"""
    n = min(len(decoded), len(truth))
    if n == 0:
        return 0.5
    return float(np.sum(decoded[:n] != truth[:n])) / n


def compute_roi_mean(img_bgr: np.ndarray) -> float:
    """
    è®¡ç®—æ„Ÿå…´è¶£åŒºåŸŸ (ROI) å¹³å‡ç°åº¦ã€‚
    ä¼˜å…ˆä½¿ç”¨ OOKDemodulator çš„ sync-based ROI æ©ç ï¼›
    è‹¥å¤±è´¥åˆ™ç”¨å…¨å›¾ä¸­å¿ƒ 50% åŒºåŸŸå‡å€¼ã€‚
    """
    try:
        from occ_gain_opt.demodulation import OOKDemodulator
        result = OOKDemodulator().demodulate(img_bgr)
        if result.roi_mask.sum() > 0:
            gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
            return float(np.mean(gray[result.roi_mask > 0]))
    except Exception:
        pass
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    h, w = gray.shape
    return float(np.mean(gray[h // 4:3 * h // 4, w // 4:3 * w // 4]))


def gain_predict_singleshot(init_gain_db: float, init_roi: float,
                            target: float = TARGET_GRAY) -> float:
    """å•æ¬¡å¢ç›Šä¼˜åŒ–å…¬å¼: G_opt(dB) = G_curr + 20Â·log10(Y_target / Y_curr)"""
    if init_roi <= 0:
        return init_gain_db
    return init_gain_db + 20.0 * float(np.log10(target / init_roi))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ ¸å¿ƒåˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def analyze_group(exp_type: str, img_type: str,
                  loader: ExperimentLoader,
                  truth: np.ndarray) -> Optional[dict]:
    """
    åˆ†æä¸€ä¸ªå®éªŒå­ç»„ (e.g. bubble/ISO) çš„ BER vs å¢ç›Šã€‚

    æ¯ä¸ª (exposure_time, ISO) ç»„åˆå¯¹åº”ä¸€ä¸ªå¢ç›Šæ¡£ï¼Œ
    æ¯æ¡£æœ‰å¤šå¼ é‡å¤å›¾ï¼ˆindex 1/10/20/30/40/50ï¼‰ï¼Œå–å¹³å‡ BERã€‚
    """
    images = loader.load_experiment(exp_type, img_type)
    if not images:
        return None

    # æŒ‰ (exposure_time, iso) åˆ†ç»„
    groups: Dict[Tuple, list] = {}
    for img in images:
        key = (round(img.exposure_time, 8), int(img.iso))
        groups.setdefault(key, []).append(img)

    print(f'\n[{exp_type}/{img_type}]  {len(groups)} ä¸ªå¢ç›Šæ¡£, '
          f'{len(images)} å¼ å›¾ç‰‡')

    gain_levels: List[float] = []
    ber_means:   List[float] = []
    ber_stds:    List[float] = []
    roi_means:   List[float] = []
    demod_rates: List[float] = []

    for key in sorted(groups.keys()):
        group_imgs = groups[key]
        gains_g, bers_g, rois_g = [], [], []
        ok_count = 0

        for exp_img in group_imgs:
            img = cv2.imread(exp_img.filepath)
            if img is None:
                continue

            gdb = exp_img.calculate_equivalent_gain()
            gains_g.append(gdb)

            # è§£è°ƒ â†’ BER
            res = demodulate_image(img)
            if res['status'] == 'ok':
                ber = compute_ber(res['bits'], truth)
                ok_count += 1
            else:
                ber = 0.5  # è§£è°ƒå¤±è´¥ â†’ éšæœºçŒœæµ‹æ°´å¹³
            bers_g.append(ber)

            # ROI å‡å€¼ï¼ˆä¾›å¢ç›Šä¼˜åŒ–å…¬å¼ä½¿ç”¨ï¼‰
            rois_g.append(compute_roi_mean(img))

        if not gains_g:
            continue

        avg_gain = float(np.mean(gains_g))
        avg_ber  = float(np.mean(bers_g))
        std_ber  = float(np.std(bers_g))
        avg_roi  = float(np.mean(rois_g))
        rate     = ok_count / len(group_imgs)

        gain_levels.append(avg_gain)
        ber_means.append(avg_ber)
        ber_stds.append(std_ber)
        roi_means.append(avg_roi)
        demod_rates.append(rate)

        tag = 'âœ…' if rate > 0 else 'âŒ'
        print(f'  {tag} gain={avg_gain:+6.1f} dB | BER={avg_ber:.4f} '
              f'Â± {std_ber:.4f} | ROI={avg_roi:5.1f} '
              f'| è§£è°ƒæˆåŠŸç‡={rate:.0%}')

    if len(gain_levels) < 2:
        print('  âš  æœ‰æ•ˆå¢ç›Šæ¡£ä¸è¶³ï¼Œè·³è¿‡æ­¤ç»„')
        return None

    gain_arr = np.array(gain_levels)
    ber_arr  = np.array(ber_means)
    roi_arr  = np.array(roi_means)

    # â”€â”€ å¢ç›Šä¼˜åŒ–æ¨¡æ‹Ÿ (å•æ¬¡å…¬å¼) â”€â”€
    idx_init      = int(np.argmin(gain_arr))
    init_gain     = float(gain_arr[idx_init])
    init_ber      = float(ber_arr[idx_init])
    init_roi      = float(roi_arr[idx_init])

    pred_gain     = gain_predict_singleshot(init_gain, init_roi)
    idx_pred      = int(np.argmin(np.abs(gain_arr - pred_gain)))
    pred_gain_act = float(gain_arr[idx_pred])
    pred_ber      = float(ber_arr[idx_pred])

    idx_best  = int(np.argmin(ber_arr))
    best_gain = float(gain_arr[idx_best])
    best_ber  = float(ber_arr[idx_best])

    # æ”¹å–„é‡: ä½¿ç”¨ç»å¯¹ BER ä¸‹é™å€¼ï¼ˆç™¾åˆ†ç‚¹ï¼‰å’Œç›¸å¯¹æ”¹å–„ï¼ˆä»…åœ¨ init_ber>0 æ—¶æœ‰æ„ä¹‰ï¼‰
    ber_abs_change = pred_ber - init_ber          # è´Ÿå€¼ = æ”¹å–„ï¼Œæ­£å€¼ = å˜å·®
    if init_ber > 0.001:
        improvement = (init_ber - pred_ber) / init_ber * 100.0
    elif pred_ber <= 0.001:
        improvement = 0.0    # éƒ½æ˜¯ 0ï¼Œæ— å˜åŒ–
    else:
        improvement = float('nan')   # åˆå§‹å·²æ˜¯ 0ï¼Œä½†ä¼˜åŒ–åå˜å·®ï¼Œç”¨ NaN æ ‡è®°

    print(f'\n  â”Œâ”€â”€ å¢ç›Šä¼˜åŒ–æ¨¡æ‹Ÿç»“æœ â”€â”€')
    print(f'  â”‚ åˆå§‹  : gain={init_gain:+.1f} dB, BER={init_ber:.4f}, '
          f'ROIå‡å€¼={init_roi:.1f}')
    print(f'  â”‚ é¢„æµ‹  : G_opt={pred_gain:+.1f} dB â†’ å®é™…é€‰ {pred_gain_act:+.1f} dB, '
          f'BER={pred_ber:.4f}')
    print(f'  â”‚ æœ€ä¼˜  : gain={best_gain:+.1f} dB, BER={best_ber:.4f}')
    if not (improvement != improvement):  # not NaN
        print(f'  â””â”€â”€ BER æ”¹å–„: {improvement:+.1f}%')
    else:
        print(f'  â””â”€â”€ åˆå§‹BERå·²ä¸º0ï¼Œä¼˜åŒ–åBER={pred_ber:.4f} (è½»å¾®è¿‡å†²)')

    return {
        'exp_type':      exp_type,
        'img_type':      img_type,
        'gain_levels':   gain_arr,
        'ber_means':     ber_arr,
        'ber_stds':      np.array(ber_stds),
        'roi_means':     roi_arr,
        'demod_rates':   np.array(demod_rates),
        'init_gain':     init_gain,
        'init_ber':      init_ber,
        'init_roi':      init_roi,
        'pred_gain':     pred_gain,
        'pred_gain_act': pred_gain_act,
        'pred_ber':      pred_ber,
        'best_gain':     best_gain,
        'best_ber':      best_ber,
        'improvement':   improvement,
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¯è§†åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def plot_group(ax: plt.Axes, data: dict) -> None:
    """åœ¨å­å›¾ä¸Šç»˜åˆ¶ BER vs å¢ç›Šæ›²çº¿ï¼Œæ ‡æ³¨åˆå§‹/é¢„æµ‹/æœ€ä¼˜ä¸‰ä¸ªå·¥ä½œç‚¹"""
    g = data['gain_levels']
    b = data['ber_means']
    e = data['ber_stds']

    ax.errorbar(g, b, yerr=e, fmt='o-', color='steelblue',
                linewidth=1.8, markersize=6, capsize=4,
                label='BER Â± std', zorder=3)

    # åˆå§‹å·¥ä½œç‚¹
    ax.axvline(data['init_gain'], color='#FF8C00', linestyle='--',
               linewidth=1.5,
               label=f"åˆå§‹ {data['init_gain']:+.0f} dB\n(BER={data['init_ber']:.3f})")
    ax.plot(data['init_gain'], data['init_ber'], 's', color='#FF8C00',
            markersize=9, zorder=5)

    # ä¼˜åŒ–é¢„æµ‹å·¥ä½œç‚¹
    ax.axvline(data['pred_gain_act'], color='#2CA02C', linestyle='--',
               linewidth=1.5,
               label=f"ä¼˜åŒ–é¢„æµ‹ {data['pred_gain_act']:+.0f} dB\n(BER={data['pred_ber']:.3f})")
    ax.plot(data['pred_gain_act'], data['pred_ber'], '^', color='#2CA02C',
            markersize=9, zorder=5)

    # æ•°æ®é›†æœ€ä¼˜
    ax.axvline(data['best_gain'], color='#D62728', linestyle=':',
               linewidth=1.5,
               label=f"æœ€ä¼˜ {data['best_gain']:+.0f} dB\n(BER={data['best_ber']:.3f})")
    ax.plot(data['best_gain'], data['best_ber'], '*', color='#D62728',
            markersize=11, zorder=5)

    ax.set_title(f"{data['exp_type']} / {data['img_type']}", fontsize=10)
    ax.set_xlabel('ç­‰æ•ˆå¢ç›Š (dB)', fontsize=9)
    ax.set_ylabel('BER', fontsize=9)
    ax.set_ylim(-0.05, 0.6)
    ax.legend(fontsize=7, loc='upper right')
    ax.grid(True, alpha=0.3)

    # è§£è°ƒæˆåŠŸç‡å‰¯åæ ‡
    ax2 = ax.twinx()
    ax2.bar(data['gain_levels'], data['demod_rates'] * 100,
            width=(data['gain_levels'].max() - data['gain_levels'].min()) / (len(data['gain_levels']) + 1),
            alpha=0.12, color='gray', label='è§£è°ƒæˆåŠŸç‡')
    ax2.set_ylabel('è§£è°ƒæˆåŠŸç‡ (%)', fontsize=8, color='gray')
    ax2.set_ylim(0, 120)
    ax2.tick_params(axis='y', labelcolor='gray', labelsize=7)


def plot_summary_bar(all_results: List[dict], output_dir: Path) -> None:
    """ç»˜åˆ¶å„å®éªŒç»„ BER æ”¹å–„æ±‡æ€»æŸ±çŠ¶å›¾"""
    labels = [f"{r['exp_type']}\n{r['img_type']}" for r in all_results]
    init_bers = [r['init_ber']   for r in all_results]
    pred_bers = [r['pred_ber']   for r in all_results]
    best_bers = [r['best_ber']   for r in all_results]

    x = np.arange(len(labels))
    width = 0.25

    fig, ax = plt.subplots(figsize=(12, 5))
    ax.bar(x - width, init_bers, width, label='åˆå§‹ BER',   color='#FF8C00', alpha=0.8)
    ax.bar(x,         pred_bers, width, label='ä¼˜åŒ–å BER', color='#2CA02C', alpha=0.8)
    ax.bar(x + width, best_bers, width, label='æœ€ä¼˜ BER',   color='#D62728', alpha=0.8)

    ax.set_xticks(x)
    ax.set_xticklabels(labels, fontsize=9)
    ax.set_ylabel('BER', fontsize=10)
    ax.set_title('å¢ç›Šä¼˜åŒ–å‰å BER å¯¹æ¯” (å„å®éªŒç»„)', fontsize=12, fontweight='bold')
    ax.legend(fontsize=9)
    ax.grid(True, axis='y', alpha=0.3)
    ax.set_ylim(0, max(max(init_bers), 0.6) * 1.15)

    plt.tight_layout()
    out = output_dir / 'ber_comparison_bar.png'
    fig.savefig(out, dpi=150, bbox_inches='tight')
    print(f'ğŸ–¼  æŸ±çŠ¶å›¾å·²ä¿å­˜: {out}')
    plt.close(fig)


def save_csv(all_results: List[dict], output_dir: Path) -> None:
    """ä¿å­˜è¯¦ç»†æ±‡æ€» CSV"""
    rows = []
    for r in all_results:
        rows.append({
            'å®éªŒ': f"{r['exp_type']}/{r['img_type']}",
            'åˆå§‹å¢ç›Š(dB)':    f"{r['init_gain']:.1f}",
            'åˆå§‹ROIå‡å€¼':      f"{r['init_roi']:.1f}",
            'åˆå§‹BER':          f"{r['init_ber']:.4f}",
            'é¢„æµ‹æœ€ä¼˜å¢ç›Š(dB)': f"{r['pred_gain']:.1f}",
            'å®é™…é€‰ç”¨å¢ç›Š(dB)': f"{r['pred_gain_act']:.1f}",
            'ä¼˜åŒ–åBER':        f"{r['pred_ber']:.4f}",
            'æ•°æ®é›†æœ€ä¼˜å¢ç›Š(dB)': f"{r['best_gain']:.1f}",
            'æ•°æ®é›†æœ€ä¼˜BER':    f"{r['best_ber']:.4f}",
            'BERæ”¹å–„(%)':       'N/A(è¿‡å†²)' if r['improvement'] != r['improvement']
                                else f"{r['improvement']:.1f}",
        })
    df = pd.DataFrame(rows)
    out = output_dir / 'ber_analysis_summary.csv'
    df.to_csv(str(out), index=False, encoding='utf-8-sig')
    print(f'ğŸ“„ æ±‡æ€» CSV å·²ä¿å­˜: {out}')


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä¸»ç¨‹åº â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main() -> None:
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # åŠ è½½çœŸå€¼
    truth = load_ground_truth(LABEL_CSV, DATA_BITS)
    print(f'âœ… å·²åŠ è½½çœŸå€¼: {len(truth)} bits')
    print(f'   å‰8ä½: {truth[:8].tolist()}')

    loader = ExperimentLoader(str(ISO_TEXP))

    experiments = [
        ('bubble',    'ISO'),
        ('bubble',    'Texp'),
        ('tap water', 'ISO'),
        ('tap water', 'Texp'),
        ('turbidity', 'ISO'),
        ('turbidity', 'Texp'),
    ]

    all_results = []
    for exp_type, img_type in experiments:
        result = analyze_group(exp_type, img_type, loader, truth)
        if result:
            all_results.append(result)

    if not all_results:
        print('âŒ æ— æœ‰æ•ˆç»“æœï¼Œè¯·æ£€æŸ¥ ISO-Texp ç›®å½•å’ŒçœŸå€¼æ–‡ä»¶')
        return

    # â”€â”€ ç»˜åˆ¶ BER vs å¢ç›Šæ›²çº¿ â”€â”€
    ncols = 3
    nrows = (len(all_results) + ncols - 1) // ncols
    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 5 * nrows))
    axes_flat = np.array(axes).flatten()

    for i, r in enumerate(all_results):
        plot_group(axes_flat[i], r)
    for j in range(i + 1, len(axes_flat)):
        axes_flat[j].set_visible(False)

    fig.suptitle('BER vs å¢ç›Š â€” å¢ç›Šä¼˜åŒ–ç®—æ³•æ•ˆæœåˆ†æ', fontsize=14, fontweight='bold')
    plt.tight_layout()
    out_curves = OUTPUT_DIR / 'ber_vs_gain_curves.png'
    fig.savefig(str(out_curves), dpi=150, bbox_inches='tight')
    print(f'\nğŸ–¼  BERæ›²çº¿å›¾å·²ä¿å­˜: {out_curves}')
    plt.close(fig)

    # â”€â”€ æ±‡æ€»æŸ±çŠ¶å›¾ â”€â”€
    plot_summary_bar(all_results, OUTPUT_DIR)

    # â”€â”€ æ‰“å°æ±‡æ€»è¡¨ â”€â”€
    print('\n' + 'â•' * 72)
    print('  æ±‡æ€»: å¢ç›Šä¼˜åŒ–ç®—æ³•å¯¹ BER çš„å½±å“')
    print('â•' * 72)
    print(f"  {'å®éªŒ':<22} {'åˆå§‹BER':>8} {'ä¼˜åŒ–åBER':>10} "
          f"{'æœ€ä¼˜BER':>9} {'BERæ”¹å–„':>10}")
    print('  ' + 'â”€' * 64)
    for r in all_results:
        imp = r['improvement']
        if imp != imp:  # NaN
            arrow, imp_str = 'â¬†', f"  +{r['pred_ber']:.4f} pts"
        elif imp > 1:
            arrow, imp_str = 'â¬‡', f"{imp:>+8.1f}%"
        elif abs(imp) <= 1:
            arrow, imp_str = 'â¡', f"{imp:>+8.1f}%"
        else:
            arrow, imp_str = 'â¬†', f"{imp:>+8.1f}%"
        print(f"  {r['exp_type']}/{r['img_type']:<14} "
              f"{r['init_ber']:>8.4f} "
              f"{r['pred_ber']:>10.4f} "
              f"{r['best_ber']:>9.4f} "
              f"  {arrow} {imp_str}")
    print('â•' * 72)

    # â”€â”€ ä¿å­˜ CSV â”€â”€
    save_csv(all_results, OUTPUT_DIR)
    print('\nâœ… BER åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨:', OUTPUT_DIR)


if __name__ == '__main__':
    main()
